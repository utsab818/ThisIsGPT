{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Token Embedding**"
      ],
      "metadata": {
        "id": "RbnfM_F1_m9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "input_ids = torch.tensor([2,3,5,1])"
      ],
      "metadata": {
        "id": "WIenUgLE_qRx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity we will take 6 as vocab_size and 3 as embedding size"
      ],
      "metadata": {
        "id": "OAgVNyvCAiXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "ZK2wNmU-Aqzt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialized weight is random\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW5reCDmBCh7",
        "outputId": "af528cf8-b243-4bf3-a7ce-ad83528fad7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These above values are optimized during LLM training and each row represent token id."
      ],
      "metadata": {
        "id": "OHRn1VBlCA8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3]))) # for id no. 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TbwG4cEB8tl",
        "outputId": "05edbe00-6d14-4007-cbb0-5cab5d6a902e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids)) # for input_ids lookup i.e. 2,3,5,1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf4fijQuCv-D",
        "outputId": "a4d5b44a-6d17-488e-9b5e-8b23f0aa2f7d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The lookup operation for the required ids is called embedding_layer.**"
      ],
      "metadata": {
        "id": "iHOmDHuTEfAB"
      }
    }
  ]
}