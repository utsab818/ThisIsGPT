{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xqPIFljuVAog"
      },
      "outputs": [],
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out,context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape # New batch of dimension b\n",
        "    queries = self.W_query(x)\n",
        "    keys = self.W_key(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1,2)\n",
        "    attn_scores = attn_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vector = attn_weights @ values\n",
        "\n",
        "    return context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja_1i-ohYMex",
        "outputId": "bfa2bfb0-92cc-4dd5-a3a5-6310106ed1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "print(d_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEmcoHAQYMUE",
        "outputId": "cd88ab8e-f7e3-4d02-9583-4572997280cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(d_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfOB9_aZXr5p",
        "outputId": "9d8f8d14-24e2-46c9-e141-9fa8507fabc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 6, 2])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, dropout=0.0)\n",
        "context_vecs = ca(batch)\n",
        "print(context_vecs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skXCMzT2Z7-7",
        "outputId": "db4e897a-54e4-4b07-dc25-53a994f3bcef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.4519,  0.2216],\n",
            "         [-0.5874,  0.0058],\n",
            "         [-0.6300, -0.0632],\n",
            "         [-0.5675, -0.0843],\n",
            "         [-0.5526, -0.0981],\n",
            "         [-0.5299, -0.1081]],\n",
            "\n",
            "        [[-0.4519,  0.2216],\n",
            "         [-0.5874,  0.0058],\n",
            "         [-0.6300, -0.0632],\n",
            "         [-0.5675, -0.0843],\n",
            "         [-0.5526, -0.0981],\n",
            "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(context_vecs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2orTxnfeROg"
      },
      "source": [
        "# Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoxn3cbReUeU"
      },
      "source": [
        "In multi head attention, we run each heads in parallel and combine them for final output context vector.\n",
        "\n",
        "In causal attention, we used one key, query and value (i.e. single head)\n",
        "If we use multiple key,query,value for same inputs and combine all the output context vectors from each to give final context vector, then it is known as multi head attention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "84GDjHY4em4p"
      },
      "outputs": [],
      "source": [
        "# when we use multiple instances of causal attention, we create multi head attention\n",
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out, num_heads, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    # create instance of causal attention class as per num_heads\n",
        "    self.heads = nn.ModuleList(\n",
        "        [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # concat all the instance\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgoTIkcDombG",
        "outputId": "38e3a472-5355-4476-dc87-d4b3e6b15fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "inputs = torch.tensor(\n",
        "    [[0.43,0.15,0.89], # Your (x^1)\n",
        "     [0.55,0.87,0.66], # journey (x^2)\n",
        "     [0.57,0.85,0.64], # starts (x^3)\n",
        "     [0.22,0.58,0.33], # with (x^4)\n",
        "     [0.77,0.25,0.10], # one (x^6)\n",
        "     [0.05,0.80,0.55]] # step (x^7)\n",
        "    )\n",
        "batch = torch.stack((inputs,inputs), dim=0)\n",
        "print(batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3a9CMnkpv-n",
        "outputId": "50182def-2ed4-4bc8-a893-e5b0afc1e818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 6, 4])\n",
            "tensor([[[-0.1471,  0.4106,  0.4675, -0.2793],\n",
            "         [-0.2493,  0.3548,  0.4651, -0.0590],\n",
            "         [-0.2782,  0.3323,  0.4578,  0.0089],\n",
            "         [-0.2636,  0.2932,  0.4108,  0.0479],\n",
            "         [-0.2197,  0.2186,  0.3167,  0.0217],\n",
            "         [-0.2420,  0.2433,  0.3495,  0.0638]],\n",
            "\n",
            "        [[-0.1471,  0.4106,  0.4675, -0.2793],\n",
            "         [-0.2493,  0.3548,  0.4651, -0.0590],\n",
            "         [-0.2782,  0.3323,  0.4578,  0.0089],\n",
            "         [-0.2636,  0.2932,  0.4108,  0.0479],\n",
            "         [-0.2197,  0.2186,  0.3167,  0.0217],\n",
            "         [-0.2420,  0.2433,  0.3495,  0.0638]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# suppose we have 2 num_heads and each head gives output as 2 dimensional context,\n",
        "# then final combination of 2 and 2 will produce 4 dimensional context matrix.\n",
        "\n",
        "context_length = batch.shape[1] # no. of tokens = 6\n",
        "d_in, d_out = 3,2\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out, num_heads=2, context_length=context_length, dropout=0.0)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs.shape)\n",
        "print(context_vecs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAAVsDqTuSsw"
      },
      "source": [
        "Now, the problem here is we are calculating each instance one by one and combining, which is highly inefficient. We can solve this with parallel computation of heads.\n",
        "\n",
        "Computing simultaneously the output of all heads by matrix multiplication."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
