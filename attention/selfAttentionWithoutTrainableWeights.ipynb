{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uBZyg56vy1N"
      },
      "source": [
        "# **Implementing a simplified attention mechanism. (without trainable weights)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9YVL-rOcvwdJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Just for illustration, let's use small embedding dimension (3-dimensional vector)\n",
        "inputs = torch.tensor(\n",
        "    [[0.43,0.15,0.89], # Your (x^1)\n",
        "     [0.55,0.87,0.66], # journey (x^2)\n",
        "     [0.57,0.85,0.64], # starts (x^3)\n",
        "     [0.22,0.58,0.33], # with (x^4)\n",
        "     [0.77,0.25,0.10], # one (x^6)\n",
        "     [0.05,0.80,0.55]] # step (x^7)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Iff6BGwCp9",
        "outputId": "8800f521-3542-4fa5-a46e-8cf65dc4777a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ],
      "source": [
        "# let's get context for 'journey' which in second input in inputs tensor.\n",
        "query = inputs[1]\n",
        "attention_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attention_scores_2[i] = torch.dot(x_i, query)\n",
        "\n",
        "print(attention_scores_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpY3huAxxuIk"
      },
      "source": [
        "Now, we normalize this attention scores to obtain weights that sum up to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ABpUr08yfq3",
        "outputId": "04de5b04-4451-4d44-c457-bdd496180cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum: tensor(1.0000)\n"
          ]
        }
      ],
      "source": [
        "# Normalization\n",
        "attn_weights_2_tmp = attention_scores_2 / torch.sum(attention_scores_2)\n",
        "print(\"Attention weights:\" , attn_weights_2_tmp)\n",
        "print(\"Sum:\", attn_weights_2_tmp.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7sarajm17Xv"
      },
      "source": [
        "better to use Softmax for normalization. (e^x1 / sum)\n",
        "\n",
        "torch softmax --> (e ^ x1-max) (To reduce overflow errors or for much more precision, torch softmax reduces max from power)\n",
        "\n",
        "In addition softmax function also ensures that the weights are positive so that there will not be any problem during summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEz3rDR116r_",
        "outputId": "af0303c9-fa58-4e1c-d1b7-3f337baff4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x) / torch.sum(torch.exp(x), dim=0) # dim=0 means summing all entries in a row\n",
        "\n",
        "attn_weights_2_naive = softmax_naive(attention_scores_2)\n",
        "print(\"Attention weights:\" , attn_weights_2_naive)\n",
        "print(\"Sum:\", attn_weights_2_naive.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb4dhZ6e16mR",
        "outputId": "08a07b97-77f9-47b2-8b85-42a36e526d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# pytorch implementation of softmax\n",
        "attn_weights_2 = torch.softmax(attention_scores_2, dim=0)\n",
        "print(\"Attention weights:\" , attn_weights_2)\n",
        "print(\"Sum:\", attn_weights_2.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWLsmsapy7Du",
        "outputId": "dc8cc59f-6afc-4f3d-99ab-863da12cba7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ],
      "source": [
        "# now let's calculate the context vector for 'journey'\n",
        "# context vector comprises is attention weight * attention scores for each and we add those.\n",
        "query = inputs[1]\n",
        "\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i,x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_2[i] * x_i\n",
        "\n",
        "print(context_vec_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdjGLbj7-fp_"
      },
      "source": [
        "We did for 'Journey', but we have to calculate for all queries.\n",
        "\n",
        "1. Attention scores\n",
        "2. Attention weights\n",
        "3. Context vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZosC23I6vrb",
        "outputId": "4837b6d1-f756-4d8b-a597-7619045b57b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ],
      "source": [
        "attn_scores = torch.empty(6,6)\n",
        "\n",
        "for i,x_i in enumerate(inputs):\n",
        "  for j,x_j in enumerate(inputs):\n",
        "    attn_scores[i,j] = torch.dot(x_i, x_j)\n",
        "\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaYkL1gXAP0l",
        "outputId": "97d3d54e-31df-4b18-a770-6c789893c0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ],
      "source": [
        "# Since for loops are very costly or computation heavy\n",
        "# We can just take inputs and it's transpose and multiply with pytorch matrix multiplication @\n",
        "\n",
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CHK3DEQ--Ns",
        "outputId": "ca1ccf59-4ddc-4603-925b-379d8cd837c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ],
      "source": [
        "# for 2-D tensor --> [row, columns] and dim=-1, or dim=1 will calculate based on columns.\n",
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "print(attn_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb8IzAc3_siQ",
        "outputId": "b44bfe70-00e0-4cc4-b10d-d602e6e459b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ],
      "source": [
        "# now calculate context vectors.\n",
        "all_context_vectors = attn_weights @ inputs\n",
        "print(all_context_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1I157hd8M1J"
      },
      "source": [
        "What is the need for trainable weights now??\n",
        "- We know that from the above example, one and journey are not related to each other, but what if in a sentence they two have strong connection. That's answered by trainable weights.\n",
        "- Apart from meaning, we have to capture the context of a sentence. This is why we need trainable weights."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
