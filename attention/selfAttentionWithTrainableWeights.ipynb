{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frdvB9rHu5Ba"
      },
      "source": [
        "# Self attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXs913HFu8aD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Just for illustration, let's use small embedding dimension (3-dimensional vector)\n",
        "inputs = torch.tensor(\n",
        "    [[0.43,0.15,0.89], # Your (x^1)\n",
        "     [0.55,0.87,0.66], # journey (x^2)\n",
        "     [0.57,0.85,0.64], # starts (x^3)\n",
        "     [0.22,0.58,0.33], # with (x^4)\n",
        "     [0.77,0.25,0.10], # one (x^6)\n",
        "     [0.05,0.80,0.55]] # step (x^7)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqgq9ZPr5_Oa"
      },
      "outputs": [],
      "source": [
        "# defining dimensions for Key,Query,Value vectors\n",
        "x_2 = inputs[1] # Journey\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ral7MyZ45jYZ"
      },
      "source": [
        "Key, Query, Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmQ-i9XJ6R5t"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "# for now let's set gradient as false, but we will set it to true during training.\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYxWI2j6o1a",
        "outputId": "da98f99f-0220-4c58-eabf-485324f69770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n",
            "Parameter containing:\n",
            "tensor([[0.1366, 0.1025],\n",
            "        [0.1841, 0.7264],\n",
            "        [0.3153, 0.6871]])\n",
            "Parameter containing:\n",
            "tensor([[0.0756, 0.1966],\n",
            "        [0.3164, 0.4017],\n",
            "        [0.1186, 0.8274]])\n"
          ]
        }
      ],
      "source": [
        "print(W_query)\n",
        "print(W_key)\n",
        "print(W_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ww6rmKD7jWc",
        "outputId": "a032287e-6ef7-4e94-95db-71e6b3ea8a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.4306, 1.4551])\n",
            "tensor([0.4433, 1.1419])\n",
            "tensor([0.3951, 1.0037])\n"
          ]
        }
      ],
      "source": [
        "# for journey\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)\n",
        "print(key_2)\n",
        "print(value_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_0B2qs57MA8",
        "outputId": "75df6167-2938-4a94-d554-a54e877f9ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys shape: torch.Size([6, 2])\n",
            "Queries shape: torch.Size([6, 2])\n",
            "Values shape: torch.Size([6, 2])\n"
          ]
        }
      ],
      "source": [
        "# let's obtain Key,value,query for all\n",
        "queries = inputs @ W_query\n",
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "print(\"Keys shape:\", keys.shape)\n",
        "print(\"Queries shape:\", queries.shape)\n",
        "print(\"Values shape:\", values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f567uEx8qTU",
        "outputId": "19966089-dfbd-48dd-ff57-f36f351b8662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2309, 1.0966],\n",
            "        [0.4306, 1.4551],\n",
            "        [0.4300, 1.4343],\n",
            "        [0.2355, 0.7990],\n",
            "        [0.2983, 0.6565],\n",
            "        [0.2568, 1.0533]])\n",
            "tensor([[0.3669, 0.7646],\n",
            "        [0.4433, 1.1419],\n",
            "        [0.4361, 1.1156],\n",
            "        [0.2408, 0.6706],\n",
            "        [0.1827, 0.3292],\n",
            "        [0.3275, 0.9642]])\n",
            "tensor([[0.1855, 0.8812],\n",
            "        [0.3951, 1.0037],\n",
            "        [0.3879, 0.9831],\n",
            "        [0.2393, 0.5493],\n",
            "        [0.1492, 0.3346],\n",
            "        [0.3221, 0.7863]])\n"
          ]
        }
      ],
      "source": [
        "print(queries)\n",
        "print(keys)\n",
        "print(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0oDm0On-ZPy"
      },
      "source": [
        "Attention score for \"Journey\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mZHb-kg8rdA",
        "outputId": "3dc7b85e-911a-4e47-fe9f-963a950652f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ],
      "source": [
        "# each query with all keys transpose. We want 6 attention scores for each query so we take transpose of keys.\n",
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c-tjqiEBsZ_"
      },
      "source": [
        "Attention scores for all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA_JjRzsBsMa",
        "outputId": "5036b9c7-f649-4f0a-8c3b-33ae44d6ffe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
            "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
            "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
            "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
            "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
            "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
          ]
        }
      ],
      "source": [
        "attn_scores = queries @ keys.T\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jniXh2MtCpcO"
      },
      "source": [
        "Now, it's time for normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubSEvnk6DxNK"
      },
      "source": [
        "Scale dot product attention (Scale by square root of key dimension and for our case it is 2)\n",
        "and apply softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f08eiUj1CsAx",
        "outputId": "56ce2ef5-0fa7-4123-b86e-9398574f5210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
            "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
            "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
            "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
            "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
            "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
          ]
        }
      ],
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights = torch.softmax(attn_scores / (d_k**0.5), dim=-1)\n",
        "print(attn_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzSZ-5USBoXJ",
        "outputId": "0710a68c-b482-4c11-a854-be25cb09d242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.3069, 0.8188])\n"
          ]
        }
      ],
      "source": [
        "# context vector for journey\n",
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_opvbUmKyyf",
        "outputId": "135c9645-4bb8-483f-b48a-7f66497ad019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]])\n"
          ]
        }
      ],
      "source": [
        "# for all\n",
        "context_vector = attn_weights @ values\n",
        "print(context_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uTsSnVoLTFX"
      },
      "source": [
        "Implementing a self attention python class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiXF6ySJLXY4"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_V1(nn.Module):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    queries = x @ self.W_query\n",
        "    keys = x @ self.W_key\n",
        "    values = x @ self.W_value\n",
        "\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vector = attn_weights @ values\n",
        "\n",
        "    return context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3KC-r_nNVVh",
        "outputId": "14990e49-ed10-4eea-9ee2-9d00f5ac70ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_V1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N4KAlSlOX42"
      },
      "source": [
        "We can improve v1 by utilizing nn.Linear of pytorch\n",
        "It has optimized matrix multiplication contributing to more stable and effective model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln9Tv2wGOc8T"
      },
      "outputs": [],
      "source": [
        "class SelfAttention_V2(nn.Module):\n",
        "  def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    queries = self.W_query(x)\n",
        "    keys = self.W_key(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vector = attn_weights @ values\n",
        "\n",
        "    return context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY2WQWFrPbgd",
        "outputId": "4006b696-9744-456c-a1fa-877c0a49b526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0739,  0.0713],\n",
            "        [-0.0748,  0.0703],\n",
            "        [-0.0749,  0.0702],\n",
            "        [-0.0760,  0.0685],\n",
            "        [-0.0763,  0.0679],\n",
            "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_V2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
